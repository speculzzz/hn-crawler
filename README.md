# Hacker News Crawler

## Project Overview
Async web crawler for Hacker News (news.ycombinator.com) with data storage.  
It is a part of Homework 16 for the OTUS course and is intended for educational purposes.

## Features

- ğŸ•·ï¸ Async crawling using `aiohttp`
- ğŸ“° Parsing top news stories and comments
- ğŸ’¾ SQLite storage with `aiosqlite`
- âš™ï¸ Configurable via `settings.py`
- ğŸ” Supports both crawling and data querying

## Installation

```bash
git clone https://github.com/speculzzz/hn-crawler.git
cd hn-crawler
pip install -r requirements.txt
```

## Usage
### Run crawler (continuous mode):

```bash
python main.py
```

### Single crawl cycle:

```bash
python main.py --once
```

### Show last 5 saved news:

```bash
python main.py --show 5
```

## Configuration

Edit config/settings.py to adjust:

- Crawl intervals
- Request timeouts
- Concurrent connections
- User agent

## Project Structure

```
hn-crawler/
â”œâ”€â”€ crawler/          # Core logic
â”‚   â”œâ”€â”€ crawler.py    # The main crawler object
â”‚   â”œâ”€â”€ fetcher.py    # HTTP client
â”‚   â”œâ”€â”€ main.py       # Main script
â”‚   â”œâ”€â”€ models.py     # Models
â”‚   â”œâ”€â”€ parser.py     # HTML parsing
â”‚   â””â”€â”€ storage.py    # Database ops
â”œâ”€â”€ config/           # Settings
â””â”€â”€ tests/            # Unit tests
```

## Requirements
- Python 3.12+
- Packages: aiohttp, beautifulsoup4, aiosqlite


## License

MIT License. See [LICENSE](LICENSE) for details.

## Author

- **speculzzz** (speculzzz@gmail.com)

---

Feel free to use it!
